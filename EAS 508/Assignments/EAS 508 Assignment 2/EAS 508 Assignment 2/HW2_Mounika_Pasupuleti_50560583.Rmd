---
title: "EAS 508 Assignment 2-- Mounika Pasupuleti and 50560583"
author: 
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(ISLR2)
library(ggplot2)
library(MASS)
library(car)
library(class)
```

In case you need to write math expression, please use the quick tutorial as the reference: https://www1.cmc.edu/pages/faculty/aaksoy/latex/latexthree.html

# Question 1 [5 points]

Describe a situation or problem from your job, everyday life, current events, etc., for which a logistic regression model would be appropriate. List some (up to 5) predictors that you might use.

<span style='color:red'>Please show your work.</span>

    Answer: 
    
**Predicting Whether the Customer Purchases the Product or Not.** 

**Situation:** Determining whether a customer would purchase a product from an online store is crucial to increasing revenue. In order to do this, we can utilize a technique known as logistic regression, which aids in predicting whether the customer will buy the product or not based on certain known characteristics.

**Predictors:** 

**1.Purchase Types or Categories:** These are the product categories or types that the consumer has already bought. Understanding the preferences and interests of the customer can be gained by examining purchase trends across several product categories. For example, if they've bought a lot of electronics, clothes, or books. By seeing what they've bought in different categories, we can understand what they like and what they're interested in.

**2.Product Reviews:** This is about what other people have said about the product. If the product has good reviews, meaning that most people who bought it liked it and said positive things about it, then other customers might be more likely to buy it too.

**3.Options for Shipping:** If there are several options to have the product delivered, such as free or quick shipping. It might be more attractive to make purchase.

**4.Past Purchase History:** This is all about what a customer has bought from the online store before. We look at how often they buy stuff, when was the last time they bought something, and how much money they spent. If they've bought things before, they're more likely to buy again, especially if they liked what they bought last time.

**5.Average Order Value:** This is about how much money the customer usually spends when they buy something from the online store. It's like finding out the average amount of money they spend each time they make a purchase. If they tend to spend a lot of money each time they buy something, they might be more likely to buy again in the future.

**6.Product Availability:** Indicates if the item is available for purchase. If it isn't available, they can't purchase it!
    





# Question 2 [20 points]

In this problem, we will use the Naive Bayes algorithm to fit a spam filter by hand.  This question does not involve any programming but only derivation and hand calculation.
Spam filters are used in all email services to classify received emails as “Spam” or “Not
Spam”. A simple approach involves maintaining a vocabulary of words that commonly
occur in “Spam” emails and classifying an email as “Spam” if the number of words fromthe dictionary that are present in the email is over a certain threshold. We are given the
vocabulary consists of 15 words

$$V = {\text{secret, offer, low, price, valued, customer, today, dollar, million, sports, is, for, play, healthy, pizza}}.$$

We will use $V_i$ to represent the $i$th word in $V$ . As our training dataset, we are also given 3 example spam messages,

- million dollar offer for today
- secret offer today
- secret is secret

and 4 example non-spam messages

- low price for valued customer
- play secret sports today
- sports is healthy
- low price pizza

Recall that the Naive Bayes classifier assumes the probability of an input depends on
its input feature. The feature for each sample is defined as $x^{(i)}=[x^{(i)}_1, x^{(i)}_2,\cdots, x^{(i)}_p], i=1,\cdots,m$
 and the class of the $i$th sample is $y^{(i)}$. In our case the length of the input vector is $p= 15$, which is equal to the number of words in the vocabulary $V$ (hint: recall that how did we define a dummy variable). Each entry $x^{(i)}_j$ is equal to the number of times word $V_j$ occurs in the $i$-th message.

1.[5 points] Calculate class prior $P(y = 0)$ and $P(y = 1)$ from the training data, where $y=0$ corresponds to spam messages, and $y=1$ corresponds to non-spam messages. Note that these class prior essentially corresponds to the frequency of each class in the training sample. Write down the predictor vectors for each spam and non-spam messages.

    Answer: 


From the above training data provided, there are 3 spam messages and 4 non-spam messages.

**Class Prior p(y=0):** The probability that a message is spam

p(y=0) = Number of spam messages/ Total number of messages = 3/7

**Class Prior p(y=1):** The probability that a message is non-spam

p(y=1) = Number of non-spam messages/ Total number of messages = 4/7

Given V=secret, offer, low, price, valued, customer, today, dollar, million, sports, is, for, play, healthy, pizza.


**Predictor vectors for Spam Messages**

million dollar offer for today

[0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0]

secret offer today

[1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]

secret is secret

[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]

**Predictor vectors for Non-Spam Messages**

low price for valued customer

[0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]

play secret sports today

[1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]

sports is healthy

[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]

low price pizza

[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]
    



2. [15 points] In the Naive Bayes model, assuming the keywords are independent of each other (this is a simplification), the likelihood of a sentence with its feature vector $x$
given a class $c$ is given by 
$$P(x|y=c)=\prod_{i=1}^{15}P(x_i|y=c), c=\{0,1\}.$$

Given a test message “today is secret”, using the Naive Bayes classier to calculate the posterior and decide whether it is spam or not spam.  <span style='color:red'>Please show your work.</span>

    Answer: 

  
Given the test message is **"today is secret"**. The probability vector for the given message is:
[1,0,0,0,0,0,1,0,0,0,1,0,0,0,0]

We have already calculated the *Prior Probabilities for spam and Non-spam class above:*
Spam: P(y=0) = 3/7
Non-spam: P(y=1) = 4/7

Now, we need to calculate the probabilities P(xi|y=0) and P(xi|y=1) for each word in the given test message(today is secret)

We know that from Bayes's theorem, we can find the posterior probability of each class:

$$P(y=c|x)=\frac{P(x|y=c)*P(y=c)}{P(x)}$$


We will now determine the probabilities of each word in the test message.

**For y = 0 which means spam message:**
$$P('today'|y=0)=\frac{1+1}{11}=\frac{2}{11}$$
$$P('is'|y=0)=\frac{1}{11}$$
$$P('secret'|y=0)=\frac{1+1+1}{11}=\frac{3}{11}$$

**For y = 1 which means Non-Spam message:** 
$$P('today'|y=1)=\frac{1}{15}$$
$$P('is'|y=1)=\frac{1}{15}$$
$$P('secret'|y=1)=\frac{1}{11}$$

**Calculating the Posterior probabilities for each class:**

For spam (y=0):
$$P(y=0|x)P(y=0)= P('today'|y=0) * P('is'|y=0) * P('secret'|y=0) * P(y=0)=\frac{2}{11}\frac{1}{11}\frac{3}{11}\frac{3}{7}=0.0019319$$

For non-spam (y=1):
$$P(y=1|x)P(y=1)= P('today'|y=1) * P('is'|y=1) * P('secret'|y=1) * P(y=0)=\frac{1}{15}\frac{1}{15}\frac{1}{15}\frac{4}{7}=0.0001693$$

Now we have to compare the posterior probabilities for both spam and non-spam messages:

P(y=0|x)=0.0019319


P(y=1|x)=0.0001693
$$P(y=0|x)>P(y=1|x)$$
Based on the above calculations, we can say that the test message "today is secret" has a higher probability of being classified as spam (y=0) than the non-spam (y=1). As a result, we would **consider this mail to be spam.**


# Question 3 [16 points]
The provided dataset is a subset of the public data from the 2022 EPA Automotive Trends Report. It will be used to study the effects of various vehicle characteristics on CO2 emissions. The dataset consists of a dataframe with 1703 observations with the following 7 variables:

- Model.Year: year the vehicle model was produced (quantitative)
- Type: vehicle type (qualitative)
- MPG: miles per gallon of fuel (quantitative)
- Weight: vehicle weight in lbs (quantitative)
- Horsepower: vehicle horsepower in HP (quantitative)
- Acceleration: acceleration time (from 0 to 60 mph) in seconds (quantitative)
- CO2: carbon dioxide emissions in g/mi (response variable)

(1).[3 points] Read the data, Fit a multiple linear regression model called model1 using CO2 as the response and all predicting variables. Using $\alpha=0.05$, which of the estimated coefficients that were statistically significant.

    Answer:
    
```{r}
# reading the dataset
data <- read.csv("emissions.csv")
head(data,3)
```
    
```{r}
data <- read.csv("emissions.csv")
model1 <- lm(CO2 ~ Model.Year + Type + MPG + Weight + Horsepower + Acceleration, data = data)
summary(model1)
```

By comparing the related p-values of each coefficient with the significance threshold $\alpha=0.05$, we can determine the statistical significance of each coefficient from the output given by model 1. At the $\alpha=0.05$ level, coefficients with p-values less than 0.05 are considered statistically significant, whereas those with p-values equal to or more than 0.05 are not.

The Coefficients for **TypeSUV, TypeTruck, TypeVan, MPG, Weight, Horsepower, and Acceleration has extremely small p-values** (6.35e-13, 5.24e-16, and < 2e-16) indicating that these coefficients **are statistically significant**. Where as the coefficient Model.year has a p-value of 0.0609, which is slightly higher than 0.05. So, it is not statistically significant.


  
    
(2).[2 points] Is the overall regression (model1) significant at an $\alpha$-level of $0.05$? Explain how you determined the answer.

    Answer:  
From the above output: The p-value corresponding with the F-statistic is given as 'p-value: < 2.2e-16' and the F-statistic value is 3309 indicating a p-value significantly less than 0.05. 

We conclude that the overall regression (model1) is significant at the $\alpha$-level of $0.05$ and reject the null hypothesis because the p-value associated with the F-statistic is significantly smaller than $\alpha$ (<< 0.05) and at least one of the model's predictors has a relationship to the response variable if the p-value for the F-statistic is less than $\alpha$ (0.05).
    
(3).[6 points] **Identifying Influential Data Points** Cook's Distances

The basic idea behind the measure is to delete the observations one at a time, each time refitting the regression model on the remaining $n-1$ observations. Then, we compare the results using all $n$ observations to the results with the $i$th observation deleted to see how much influence the observation has on the analysis. Analyzed as such, we are able to assess the potential impact each data point has on the regression analysis. One of such a method is called `Cook's distance`. To learn more on Cook's distance in R, see https://rpubs.com/DragonflyStats/Cooks-Distance.

Create a plot for the Cook’s Distances (use model1). Using a threshold of $1$, are there any outliers? If yes, which data points?

    Answer: 
    
```{r}
# Calculating the Cook's distances
cooksdis <- cooks.distance(model1)
plot(cooksdis, type="h", lwd=4, col="orange", xlab='observation', ylab = "Cook's Distance", main="Cook's Distance")
abline(h = 1,col = "green")

# From the above cook's distance here we are identifying the outliers 
finding_outliers <- which(abs(cooksdis) > 1)
if (length(finding_outliers) > 0) {
  cat("outliers were found. There are", finding_outliers, "outlier data points using cook's distance method.")
} else {
  cat("No outliers were found using Cook's distance method.\n")
}

```
    
    
(4).[5 points] **Detecting Multicollinearity Using Variance Inflation Factors (VIF)** 

The effects that multicollinearity can have on our regression analyses and subsequent conclusions, how can we tell if multicollinearity is present in our data? A variance inflation factor exists for each of the predictors in a multiple regression model. For example, the variance inflation factor for the estimated regression coefficient $\beta_j$—denoted $VIF_j$ —is just the factor by which the variance of $\beta_j$ is "inflated" by the existence of correlation among the predictor variables in the model.

In particular, the variance inflation factor for the $j$th predictor is: $ VIF_j=\frac{1}{1-R_j^2}$ where $R^2_j$  is the $R^2$-value obtained by regressing the jth predictor on the remaining predictors. 

A VIF of $1$ means that there is no correlation among the $j$th predictor and the remaining predictor variables, and hence the variance of $\beta_j$ is not inflated at all. The general rule of thumb is that VIFs exceeding $4$ warrant further investigation, while VIFs exceeding $10$ are signs of serious multicollinearity requiring correction. For more information, see https://search.r-project.org/CRAN/refmans/usdm/html/vif.html.

Calculate the VIF of each predictor (use model1). Using a threshold of $\max(10, \frac{1}{1-R^2})$ what conclusions can you make regarding multicollinearity?

```{r}
# Calculate VIF for each predictor in model1
vif(model1)
```

From the above output we can conclude that the GVIF value for Model.year, Weight and Horsepower has higher threshold value which is above 10 indicating that there are signs of serious multicollinearity requiring correction.

For MPG and Acceleration the threshold value is exceeding 4 in which further investigation is warranted for potential multicollinearity.

For Type, the GVIF is 3.29 which is below threshold value, which indicates that there is no significant multicollinearity.


```{r}
VIF_threshold <- max(10, 1/(1-summary(model1)$r.squared))
cat("VIF threshold:", VIF_threshold)
```
The output for VIF threshold is 16.62808. Since there are some predictors which are having the VIF values less than 10 the test is negative for multicollinearity. 

# Question 4 [16 points]

(1).  Using the GermanCredit data set german.credit (Download the dataset from http://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29 and read the description), use logistic regression to find a good predictive model for whether credit applicants are good credit risks or not. Show your model (factors used and their coefficients), the output, and the quality of fit. You can use the glm function in R. To get a logistic regression (logit) model on data where the response is either zero or one, use family=binomial in your glm function call. Steps including:

   a.[2 points] load the dataset 
   
    Answer:  
```{r}
#set.seed(1)
german_credit_data <- read.table("german.data", header = FALSE, sep = "", fill = TRUE)
head(german_credit_data)
```

   b.[4 points] explore the dataset, including summary of dataset, types of predictors, if there are categorical predictors, convert the predictors to factors. 
   
    Answer: 

```{r}
summary(german_credit_data)
```

```{r}
str(german_credit_data)
```

```{r}
sapply(german_credit_data, class)
```

```{r}
categorical_predictors <- c("V1", "V3", "V4", "V6", "V7", "V9", "V10", "V12", "V14", "V15", "V17", "V19", "V20")
german_credit_data[, categorical_predictors] <- lapply(german_credit_data[, categorical_predictors], factor)
head(german_credit_data)
```

   
   c.[2 points] Column V21 represents the target, 1 = Good, 2 = Bad, convert value the values to 0 and 1, respectively.
    
    Answer:  
   
```{r}
german_credit_data$V21 <- factor(german_credit_data$V21, levels = c(1, 2), labels = c(0, 1))
table(german_credit_data$V21)
```
   
   d.[2 points]  split the dataset to training and test dataset with 90% and 10% of the data points, respectively.
   
    Answer: 

```{r}
set.seed(39)
indices <- sample(1:nrow(german_credit_data), 0.9 * nrow(german_credit_data))
training_data <- german_credit_data[indices, ]
test_data <- german_credit_data[-indices, ]
head(training_data)
head(test_data)
```

   
   
   e.[3 points] use the training dataset to get a logistic regression (logit) model on data where the response is either zero or one, use family=binomial in your glm function call.
   
    Answer: 
    

```{r}
logistic_model <- glm(V21 ~ ., data = training_data, family = binomial(link = "logit"))
summary(logistic_model)
```
    
  f.[4 points] use the model to make prediction on the the training dataset, and test dataset, give the confusion matrices and accuracy for each dataset.

    Answer:
    
```{r}    
#Training dataset predictions
predict_train <- predict(logistic_model, type = "response", new_data = training_data)
predict_train  <- ifelse(predict_train  >= 0.5, 1, 0)
conf_matrix_for_train <- table(predict=predict_train, actual=training_data$V21)
training_accuracy <- sum(diag(conf_matrix_for_train)) / sum(conf_matrix_for_train)
conf_matrix_for_train
cat("The accuracy for training data is: ", training_accuracy)


#Test dataset predictions
predict_test <- predict(logistic_model, type = "response", newdata = test_data)
predict_test <- ifelse(predict_test >= 0.5, 1, 0)
conf_matrix_for_test <- table(predict=predict_test, actual=test_data$V21)
test_accuracy <- sum(diag(conf_matrix_for_test)) / sum(conf_matrix_for_test)
conf_matrix_for_test
cat("The accuracy for test data is: " , test_accuracy)
```


(2). [4 points] Because the model gives a result between $0$ and $1$, it requires setting a threshold probability to separate between “good” and “bad” answers. In this data set, they estimate that incorrectly identifying a bad customer as good, is $5$ times worse than incorrectly classifying a good customer as bad. Determine a good threshold probability based on your model <span style='color:red'>(please demonstrate your reasoning.)</span>

    Answer: 


```{r}
false_pos = 5
false_neg = 1
thresholds <- seq(0, 1, by = 0.001)
costs <- data.frame(Threshold = thresholds, overall_cost = NA)
actual_test_factor <- factor(test_data$V21, levels = c(0, 1))
for (i in seq_along(thresholds)) {
  threshold <- thresholds[i]
  predicted_test_factor <- factor(ifelse(predict_test > threshold, 1, 0), levels = c(0, 1))
  conf_matrix <- table(Predicted = predicted_test_factor, Actual = actual_test_factor)
  fp <- ifelse(is.na(conf_matrix["1", "0"]), 0, conf_matrix["1", "0"])
  fn <- ifelse(is.na(conf_matrix["0", "1"]), 0, conf_matrix["0", "1"])
  total_cost <- (fp * false_pos) + (fn * false_neg)
  costs$overall_cost[i] <- total_cost
}
optimal_threshold <- costs[which.min(costs$overall_cost),]
cat("Good threshold probability:", optimal_threshold$Threshold)
```


# Question 5 [28 points]
In this problem, you will develop a model to predict whether a given car gets high or low gas mileage based on the `Auto` data set.

(1).[2 points] Create a binary variable, `mpg01`, that contains a $1$ if mpg contains a value above its median, and a $0$ if mpg contains a value below
its median. You can compute the median using the `median()` function. Note you may find it helpful to use the data.frame() function to create a single data set containing both `mpg01` and
the other `Auto` variables.

    Answer: 
    
```{r}
data(Auto)
head(Auto,5)

```

```{r}
median_of_mpg <- median(Auto$mpg)
Auto$mpg01 <- ifelse(Auto$mpg > median_of_mpg, 1, 0)
```
    
    
(2).[4 points] Explore the data graphically in order to investigate the association between `mpg01` and the other features. Which of the other
features seem most likely to be useful in predicting `mpg01`? Scatterplots and boxplots may be useful tools to answer this question.
Describe your findings.

    Answer: 
```{r}
cor(Auto[,-9])
```

```{r}
#Scatterplot 
colors <- c("red", "blue")[Auto$mpg01 + 1]
pairs(~ mpg + cylinders + displacement + horsepower + weight + acceleration + year + origin + mpg01 , data = Auto, main = "Scatterplot Matrix", col=colors)
```



```{r}
#Boxplot
par(mfrow = c(2, 4))
invisible(lapply(1:8, function(i) {
  boxplot(Auto[, i] ~ Auto$mpg01, main = names(Auto)[i], ylab = "")
}))
```
From the correlation matrix, scatterplot and boxplots, we can say that the cylinders, weight, displacement, horsepower are useful in predicting mpg01.


(3).[2 points] Split the data into a training set and a test set.

    Answer: 
    
```{r}
# Splitting the data into training and testing in 70:30 ratio.
set.seed(32)
no_of_rows <- nrow(Auto)
vector_indices <- sample(1:no_of_rows)
training_set_size <- round(0.7 * no_of_rows)
training_set_indices <- vector_indices[1:training_set_size]
training_data <- Auto[training_set_indices, ]
testing_data <- Auto[-training_set_indices, ]
dim(training_data)
dim(testing_data)

```
    
    
    
(4).[3 points] Perform LDA on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in (2). What is the test error of the model obtained?


    Answer: 
    
```{r}
library(MASS)
data1 = training_data
lda_model <- lda(mpg01 ~ cylinders + displacement + horsepower + weight , data = data1)
lda_model
lda_predict_mpg01 <- predict(lda_model, testing_data)
lda_test_error <- lda_predict_mpg01$class != testing_data$mpg01
lda_test_error <- mean(lda_test_error)
lda_test_error
```
    
    
    
(5).[3 points] Perform QDA on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in (2). What is the test error of the model obtained?


    Answer: 
```{r}
qda_model <- qda(mpg01 ~ cylinders + displacement + horsepower + weight , data = data1)
qda_model
qda_predict_mpg01 <- predict(qda_model, testing_data)
qda_test_error <- qda_predict_mpg01$class != testing_data$mpg01
qda_test_error <- mean(qda_test_error)
qda_test_error
```    
    
    
    
    
(6). [3 points] Perform logistic regression on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in (2). What is the test error of the model obtained?


    Answer:
    
```{r}
logistic <- mpg01 ~ cylinders + displacement + horsepower + weight
logistic_reg <- glm(logistic, data = training_data, family = binomial)
logistic_reg
predict_mpg01 <- predict(logistic_reg, newdata = testing_data, type = "response")
prediction <- ifelse(predict_mpg01 > 0.5, 1, 0)
lg_test_error <- mean(prediction != testing_data$mpg01)
lg_test_error
```
 
    
(7). [3 points] Perform naive Bayes on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in (2). What is the test error of the model obtained?


    Answer: 
```{r}
library(e1071)
nb <- naiveBayes(mpg01 ~ cylinders + displacement + horsepower + weight, data = training_data)
nb
nb_predict_mpg01 <- predict(nb, testing_data)
nb_test_error <- nb_predict_mpg01 != testing_data$mpg01
nb_test_error <- mean(nb_test_error)
nb_test_error
```

    
(8). [5 points] Perform KNN on the training data in order to predict `mpg01` using the variables that seemed most associated with `mpg01` in (2). What is the test error of the model obtained? Which value of K seems to perform the best on this data set?

    Answer: 
```{r}
library(class)
values_of_k <- seq(1, 10, by = 2)
error <- length(values_of_k)
knn_errors <- numeric(error)
knn_predictors <- c("cylinders", "displacement", "horsepower", "weight")
for (i in seq_along(values_of_k)) {
  knn_model_pred <- knn(training_data[, knn_predictors], 
                  testing_data[, knn_predictors], 
                  training_data$mpg01, k = values_of_k[i])
  knn_errors[i] <- mean(knn_model_pred != testing_data$mpg01)
  cat("If the value of k =", values_of_k[i], ", The test error is:", knn_errors[i], "\n")
}
best_k_values <- values_of_k[which.min(knn_errors)]
best_k_values
# The value of k=3 having test error of 0.1016949 performs the best on this data set.
```



(9).[3 points] Compare the above models, which models do you think is the best, why?

    Answer: The test error for logisitic regression: 0.1186441
    The test error for LDA (Linear Discriminant Analysis): 0.1271186
    The test error for QDA (Quadratic Discriminant Analysis): 0.1186441
    The test error for Naive Bayes: 0.1271186
    The test error for KNN (K-Nearest Neighbors) at k = 3(best): 0.1016949
    Considering the outputs from all the models(LDA, QDA, Naive Bayes, KNN) KNN performs better on this data set with lower test error value of 0.1016949, which means that this model best suits for predicting whether an automobile would obtain high or low gas mileage on the specific predictors.
    
    
    
    
    
    
    
    
    
    